{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13236</td>\n",
       "      <td>67210</td>\n",
       "      <td>Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13239</td>\n",
       "      <td>46552</td>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13236  67210  Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...       NOT   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "13239  46552  #Spanishrevenge vs. #justice #HumanRights and ...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "2           NaN       NaN  \n",
       "3           UNT       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "13235       TIN       IND  \n",
       "13236       NaN       NaN  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "13239       NaN       NaN  \n",
       "\n",
       "[13240 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"training-v1/offenseval-training-v1.tsv\",sep='\\t')\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=df[[\"tweet\"]]\n",
    "labels = df[[\"subtask_a\"]]\n",
    "tweets1 = copy.deepcopy(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1['tidy_tweet'] = np.vectorize(remove_pattern)(tweets['tweet'], \"@[\\w]*\") \n",
    "tweets1['tidy_tweet'] = tweets1['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "tweets1['tidy_tweet'] = tweets1['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "tokenized_tweet = tweets1['tidy_tweet'].apply(lambda x: x.split())\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "untokenized_data =[' '.join(tweet) for tweet in tokenized_tweet]\n",
    "vectorizer = vectorizer.fit(untokenized_data)\n",
    "vectors = vectorizer.transform(untokenized_data).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = labels['subtask_a'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectors1=vectors#this line was used for memory error debugging\n",
    "labels1=labels#this line was used for memory error debugging\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors1, labels1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(multi_class='auto', solver='newton-cg',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score1=f1_score(test_labels, classifier.predict(test_vectors), average='macro') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6763586869523308\n"
     ]
    }
   ],
   "source": [
    "print(f1_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2106  121]\n",
      " [ 670  413]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, classifier.predict(test_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Average Tweet Length Instead of Whole Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets1['tidy_tweet'][0]\n",
    "total_tweet = np.array([])\n",
    "total_label = np.array([])\n",
    "temp = []\n",
    "counter = 0\n",
    "for tweets in tweets1['tidy_tweet']:\n",
    "    if len(tweets.split()) <= 22:\n",
    "        total_tweet = np.append(total_tweet,tweets)\n",
    "        total_label = np.append(total_label,labels.iloc[counter])\n",
    "    counter += 1\n",
    "#         total_tweet.append(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' She should ask a few native Americans what their take on this is ',\n",
       "       '  Go home you re drunk     #MAGA #Trump          URL',\n",
       "       ' Someone should veTaken  this piece of shit to a volcano    ',\n",
       "       ..., ' And why report this garbage   We don t give a crap ',\n",
       "       ' Pussy',\n",
       "       '#Spanishrevenge vs  #justice #HumanRights and #FreedomOfExpression #Spain is a  #fakedemocracy                #cddr #shameonSpain #WakeupEurope  URL'],\n",
       "      dtype='<U231')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1 = pd.DataFrame({'tidy_tweet': total_tweet[:]})\n",
    "# tweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame({'subtask_a': total_label[:]})\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = tweets1['tidy_tweet'].apply(lambda x: x.split())\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "untokenized_data =[' '.join(tweet) for tweet in tokenized_tweet]\n",
    "vectorizer = vectorizer.fit(untokenized_data)\n",
    "vectors = vectorizer.transform(untokenized_data).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors1=vectors\n",
    "labels1 = labels['subtask_a'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors1=vectors#this line was used for memory error debugging\n",
    "labels1=labels#this line was used for memory error debugging\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors1, labels1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(multi_class='auto', solver='newton-cg',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score1=f1_score(test_labels, classifier.predict(test_vectors), average='macro') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6672120729482001\n"
     ]
    }
   ],
   "source": [
    "print(f1_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1441   35]\n",
      " [ 439  215]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, classifier.predict(test_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Class Balancing Technique - Upsampling/Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"training-v1/offenseval-training-v1.tsv\",sep='\\t')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>77444</td>\n",
       "      <td>@USER @USER Oh noes! Tough shit.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13223</td>\n",
       "      <td>63482</td>\n",
       "      <td>@USER is advocating for conduct within bounds ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13227</td>\n",
       "      <td>87416</td>\n",
       "      <td>@USER @USER @USER @USER Liars like the Antifa ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "5      97670                  @USER Liberals are all Kookoo !!!       OFF   \n",
       "6      77444                   @USER @USER Oh noes! Tough shit.       OFF   \n",
       "...      ...                                                ...       ...   \n",
       "13223  63482  @USER is advocating for conduct within bounds ...       OFF   \n",
       "13227  87416  @USER @USER @USER @USER Liars like the Antifa ...       OFF   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "3           UNT       NaN  \n",
       "5           TIN       OTH  \n",
       "6           UNT       NaN  \n",
       "...         ...       ...  \n",
       "13223       TIN       GRP  \n",
       "13227       TIN       GRP  \n",
       "13235       TIN       IND  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "\n",
       "[4400 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.loc[df1.subtask_a == \"OFF\"]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =  pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13223</td>\n",
       "      <td>63482</td>\n",
       "      <td>@USER is advocating for conduct within bounds ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13227</td>\n",
       "      <td>87416</td>\n",
       "      <td>@USER @USER @USER @USER Liars like the Antifa ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17640 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13223  63482  @USER is advocating for conduct within bounds ...       OFF   \n",
       "13227  87416  @USER @USER @USER @USER Liars like the Antifa ...       OFF   \n",
       "13235  95338  @USER Sometimes I get strong vibes from people...       OFF   \n",
       "13237  82921  @USER And why report this garbage.  We don't g...       OFF   \n",
       "13238  27429                                        @USER Pussy       OFF   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "2           NaN       NaN  \n",
       "3           UNT       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "13223       TIN       GRP  \n",
       "13227       TIN       GRP  \n",
       "13235       TIN       IND  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "\n",
       "[17640 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=df3[[\"tweet\"]]\n",
    "labels = df3[[\"subtask_a\"]]\n",
    "tweets1 = copy.deepcopy(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1['tidy_tweet'] = np.vectorize(remove_pattern)(tweets['tweet'], \"@[\\w]*\") \n",
    "tweets1['tidy_tweet'] = tweets1['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "tweets1['tidy_tweet'] = tweets1['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "tokenized_tweet = tweets1['tidy_tweet'].apply(lambda x: x.split())\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "untokenized_data =[' '.join(tweet) for tweet in tokenized_tweet]\n",
    "vectorizer = vectorizer.fit(untokenized_data)\n",
    "vectors = vectorizer.transform(untokenized_data).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = labels['subtask_a'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors1=vectors#this line was used for memory error debugging\n",
    "labels1=labels#this line was used for memory error debugging\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors1, labels1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(multi_class='auto', solver='newton-cg',)\n",
    "classifier.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score1=f1_score(test_labels, classifier.predict(test_vectors), average='macro') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7651907444651175\n"
     ]
    }
   ],
   "source": [
    "print(f1_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1835  437]\n",
      " [ 594 1544]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, classifier.predict(test_vectors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using No. Of Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=df[[\"tweet\"]]\n",
    "labels = df[[\"subtask_a\"]]\n",
    "tweets1 = copy.deepcopy(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1['tidy_tweet'] = np.vectorize(remove_pattern)(tweets['tweet'], \"[\\w]*\") \n",
    "tweets1['tidy_tweet'] = tweets1['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "tweets1['tidy_tweet'] = tweets1['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "tokenized_tweet = tweets1['tidy_tweet'].apply(lambda x: x.split())\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>ntive Americns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>volcno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13235</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people...</td>\n",
       "      <td>million murder dangerou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13236</td>\n",
       "      <td>Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13237</td>\n",
       "      <td>@USER And why report this garbage.  We don't g...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13238</td>\n",
       "      <td>@USER Pussy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13239</td>\n",
       "      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n",
       "      <td>#fkedemocrcy #shmeon #WkeupEurope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "0      @USER She should ask a few native Americans wh...   \n",
       "1      @USER @USER Go home you’re drunk!!! @USER #MAG...   \n",
       "2      Amazon is investigating Chinese employees who ...   \n",
       "3      @USER Someone should'veTaken\" this piece of sh...   \n",
       "4      @USER @USER Obama wanted liberals &amp; illega...   \n",
       "...                                                  ...   \n",
       "13235  @USER Sometimes I get strong vibes from people...   \n",
       "13236  Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...   \n",
       "13237  @USER And why report this garbage.  We don't g...   \n",
       "13238                                        @USER Pussy   \n",
       "13239  #Spanishrevenge vs. #justice #HumanRights and ...   \n",
       "\n",
       "                              tidy_tweet  \n",
       "0                         ntive Americns  \n",
       "1                                         \n",
       "2                                         \n",
       "3                                 volcno  \n",
       "4                                         \n",
       "...                                  ...  \n",
       "13235            million murder dangerou  \n",
       "13236                                     \n",
       "13237                                     \n",
       "13238                                     \n",
       "13239  #fkedemocrcy #shmeon #WkeupEurope  \n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "untokenized_data =[' '.join(tweet) for tweet in tokenized_tweet]\n",
    "vectorizer = vectorizer.fit(untokenized_data)\n",
    "vectors = vectorizer.transform(untokenized_data).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = labels['subtask_a'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors1=vectors#this line was used for memory error debugging\n",
    "labels1=labels#this line was used for memory error debugging\n",
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors1, labels1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(multi_class='auto', solver='newton-cg',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(multi_class='auto', solver='newton-cg',)\n",
    "classifier.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score1=f1_score(test_labels, classifier.predict(test_vectors), average='macro') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43684379332511275\n"
     ]
    }
   ],
   "source": [
    "print(f1_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2137   50]\n",
      " [1073   50]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_labels, classifier.predict(test_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
